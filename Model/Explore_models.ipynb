{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yichen/anaconda2/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from train_inception import feature_extraction_InV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width=299\n",
    "img_height = 299\n",
    "train_data_dir = \"all_image_final/\"\n",
    "test_data_dir=\"data/test\"\n",
    "num_image=1800\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 4 classes.\n",
      "120/120 [==============================] - 860s 7s/step\n",
      "(1800, 2048) (1800, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,model=feature_extraction_InV3(img_width, img_height,\n",
    "                        train_data_dir,\n",
    "                        num_image,\n",
    "                        epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model=LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\",max_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=4000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model.fit(X_train,y_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_scores_lg = cross_val_score(lg_model, X_train,y_train.argmax(axis=1),cv=5,scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_acc_lg=cross_val_score(lg_model,X_train,y_train.argmax(axis=1),cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4916992176852567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_scores_lg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846111111111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_acc_lg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC MODEL TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[1,10,50,100]}\n",
    "clf = GridSearchCV(lg_model, parameters,scoring='neg_log_loss')\n",
    "clf.fit(X_train,y_train.argmax(axis=1))\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GBC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc_model=GradientBoostingClassifier(learning_rate=0.05,n_estimators=800,\n",
    "                                    max_depth=3,subsample=0.5,max_features='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        1181.0089          47.6549           13.80m\n",
      "         2        1129.3944          40.1024           13.26m\n",
      "         3        1081.2473          35.1313           13.01m\n",
      "         4        1042.4116          34.2153           12.83m\n",
      "         5        1004.0056          32.4823           12.66m\n",
      "         6         962.8129          30.1733           12.50m\n",
      "         7         922.0893          25.2924           12.54m\n",
      "         8         901.5954          24.0733           12.36m\n",
      "         9         863.7018          21.4796           12.28m\n",
      "        10         836.8827          22.6573           12.21m\n",
      "        20         630.7111          12.2460           11.88m\n",
      "        30         505.4501           6.6884           11.45m\n",
      "        40         417.1423           4.5486           11.11m\n",
      "        50         348.4664           2.5796           10.89m\n",
      "        60         300.2507           1.7621           10.88m\n",
      "        70         262.0929           1.1619           10.90m\n",
      "        80         222.3884           1.1755           10.83m\n",
      "        90         201.5694           0.3959           10.67m\n",
      "       100         177.1540           0.4655           10.52m\n",
      "       200          77.9218          -0.0616            8.79m\n",
      "       300          38.7833           0.0321            7.28m\n",
      "       400          19.3074          -0.0018            5.78m\n",
      "       500           9.1948          -0.0030            4.28m\n",
      "       600           4.4990          -0.0021            2.84m\n",
      "       700           2.4090           0.0031            1.41m\n",
      "       800           1.2112           0.0006            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=3,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=800,\n",
       "              presort='auto', random_state=None, subsample=0.5, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_model.fit(X_train,y_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         739.8094          58.6577            1.83m\n",
      "         2         673.2875          48.5734            1.81m\n",
      "         3         623.5545          41.5884            1.80m\n",
      "         4         577.3329          36.1885            1.80m\n",
      "         5         539.4282          28.4541            1.79m\n",
      "         6         494.6196          26.8402            1.78m\n",
      "         7         476.8754          23.0570            1.77m\n",
      "         8         446.9807          18.1031            1.76m\n",
      "         9         412.7416          17.1357            1.75m\n",
      "        10         395.4369          15.0389            1.75m\n",
      "        20         244.4222           5.1527            1.64m\n",
      "        30         160.4001           2.4965            1.54m\n",
      "        40         123.0985           0.5649            1.45m\n",
      "        50          90.8184           0.7224            1.36m\n",
      "        60          74.1919           0.2989            1.27m\n",
      "        70          61.2816           0.2200            1.18m\n",
      "        80          49.9945           0.3060            1.09m\n",
      "        90          37.5447           0.1189           59.68s\n",
      "       100          31.1133          -0.0143           54.14s\n",
      "       200           5.5317          -0.0020            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         741.2856          60.9511            1.83m\n",
      "         2         678.7668          49.6622            1.79m\n",
      "         3         620.7718          41.7987            1.80m\n",
      "         4         577.0501          39.4746            1.79m\n",
      "         5         530.4657          27.1186            1.78m\n",
      "         6         502.6041          24.4926            1.77m\n",
      "         7         464.6401          20.4653            1.76m\n",
      "         8         438.9219          17.8506            1.75m\n",
      "         9         406.1701          16.9539            1.74m\n",
      "        10         381.3519          14.9850            1.73m\n",
      "        20         230.4024           4.6250            1.67m\n",
      "        30         157.5138           1.5716            1.62m\n",
      "        40         111.1232           0.5966            1.51m\n",
      "        50          89.1481           0.6121            1.41m\n",
      "        60          71.5919           0.2386            1.30m\n",
      "        70          57.5418           0.1462            1.20m\n",
      "        80          44.4484           0.0263            1.11m\n",
      "        90          37.7914           0.1334            1.01m\n",
      "       100          31.8752           0.0906           54.99s\n",
      "       200           4.5675           0.0040            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         736.4779          61.0570            1.81m\n",
      "         2         680.7191          49.1128            1.82m\n",
      "         3         625.1894          38.2339            1.80m\n",
      "         4         572.2773          29.4703            1.78m\n",
      "         5         539.8442          29.5779            1.77m\n",
      "         6         502.6337          24.7573            1.76m\n",
      "         7         468.9112          22.8411            1.77m\n",
      "         8         451.0821          17.9064            1.75m\n",
      "         9         414.0788          14.0315            1.74m\n",
      "        10         396.0086          14.1811            1.73m\n",
      "        20         234.3592           3.6503            1.63m\n",
      "        30         170.3939           0.9858            1.53m\n",
      "        40         124.0439           0.7064            1.44m\n",
      "        50          96.5406           0.5366            1.35m\n",
      "        60          76.8731           0.2203            1.26m\n",
      "        70          62.0735           0.3427            1.17m\n",
      "        80          52.0832           0.3117            1.07m\n",
      "        90          41.6101          -0.0661           58.96s\n",
      "       100          34.8539           0.0878           53.60s\n",
      "       200           6.0338           0.0249            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         682.4278          67.9805            3.67m\n",
      "         2         613.3106          45.1316            3.71m\n",
      "         3         548.4309          42.7559            3.81m\n",
      "         4         494.3974          35.9267            3.74m\n",
      "         5         438.3776          27.5043            3.74m\n",
      "         6         402.5669          26.2493            3.82m\n",
      "         7         359.2054          22.4475            3.81m\n",
      "         8         330.8320          17.2778            3.77m\n",
      "         9         305.1574          15.5400            3.85m\n",
      "        10         278.5146          14.9486            3.84m\n",
      "        20         130.1560           4.0873            3.67m\n",
      "        30          75.0531           1.2992            3.44m\n",
      "        40          46.6643           0.3203            3.17m\n",
      "        50          29.3397           0.3394            2.95m\n",
      "        60          19.1756           0.1956            2.75m\n",
      "        70          14.4505           0.1380            2.52m\n",
      "        80          10.0198           0.0885            2.30m\n",
      "        90           7.2963           0.0409            2.10m\n",
      "       100           4.8896           0.0106            1.89m\n",
      "       200           0.2415          -0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         697.6820          58.4750            3.71m\n",
      "         2         616.9264          54.6735            3.68m\n",
      "         3         551.4798          43.2437            3.80m\n",
      "         4         504.3163          35.8885            3.80m\n",
      "         5         450.6736          29.4687            3.84m\n",
      "         6         410.2200          26.7973            3.88m\n",
      "         7         371.0972          18.9045            3.84m\n",
      "         8         347.5396          19.6843            3.80m\n",
      "         9         304.0993          15.7836            3.78m\n",
      "        10         276.3972          12.0532            3.77m\n",
      "        20         136.3407           3.9555            3.57m\n",
      "        30          71.2292           1.1675            3.34m\n",
      "        40          46.2084           0.4882            3.04m\n",
      "        50          29.4205           0.3445            2.80m\n",
      "        60          19.2698           0.1781            2.58m\n",
      "        70          14.3144           0.1538            2.38m\n",
      "        80           9.8750           0.0425            2.19m\n",
      "        90           6.9669           0.0264            1.99m\n",
      "       100           5.3182           0.0034            1.81m\n",
      "       200           0.2387           0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         692.5963          65.6669            3.43m\n",
      "         2         612.4397          48.4313            3.53m\n",
      "         3         554.9877          42.9498            3.56m\n",
      "         4         496.0502          36.0583            3.53m\n",
      "         5         449.0527          26.7864            3.52m\n",
      "         6         415.2480          22.8068            3.49m\n",
      "         7         374.2276          21.2129            3.46m\n",
      "         8         342.5670          17.7880            3.44m\n",
      "         9         314.8505          14.7263            3.43m\n",
      "        10         286.3479          12.8256            3.40m\n",
      "        20         142.2051           3.9364            3.19m\n",
      "        30          76.1877           0.9202            2.99m\n",
      "        40          50.3690           0.6903            2.77m\n",
      "        50          34.1797           0.3106            2.57m\n",
      "        60          23.2263           0.1691            2.40m\n",
      "        70          16.5684           0.1193            2.22m\n",
      "        80          11.9438           0.0937            2.04m\n",
      "        90           8.2267          -0.0032            1.88m\n",
      "       100           5.9233           0.0268            1.71m\n",
      "       200           0.2735           0.0003            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        1120.2984          89.4585            2.89m\n",
      "         2        1033.0772          69.0831            2.92m\n",
      "         3         959.0723          62.4475            3.05m\n",
      "         4         886.7422          51.8657            3.14m\n",
      "         5         829.5604          45.3215            3.18m\n",
      "         6         787.3641          39.1177            3.13m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7         742.6551          36.5268            3.07m\n",
      "         8         690.3067          29.7356            3.02m\n",
      "         9         660.1904          27.7796            2.97m\n",
      "        10         626.7575          20.1453            3.03m\n",
      "        20         411.3904           8.4889            2.74m\n",
      "        30         303.2012           2.7336            2.53m\n",
      "        40         224.9165           2.0268            2.36m\n",
      "        50         183.8837           0.4254            2.19m\n",
      "        60         160.5803           0.3970            2.04m\n",
      "        70         132.7830           0.6957            1.88m\n",
      "        80         109.5016          -0.2291            1.73m\n",
      "        90          93.0890          -0.0715            1.58m\n",
      "       100          80.3068          -0.0150            1.43m\n",
      "       200          20.9940           0.0583            0.00s\n",
      "{'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[3,5]}\n",
    "clf = GridSearchCV(my_model2, parameters,scoring='neg_log_loss')\n",
    "clf.fit(X_train,y_train.argmax(axis=1))\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         942.2228          38.0936            9.21m\n",
      "         2         902.7338          33.2533            9.04m\n",
      "         3         862.3998          28.7308            8.97m\n",
      "         4         826.9894          26.8498            9.31m\n",
      "         5         800.2476          26.4855            9.25m\n",
      "         6         764.2809          24.0605            9.17m\n",
      "         7         734.8693          21.2154            9.14m\n",
      "         8         705.1549          21.6638            9.09m\n",
      "         9         683.8947          18.3034            9.07m\n",
      "        10         659.1562          16.8299            9.01m\n",
      "        20         483.5104           7.4554            8.90m\n",
      "        30         394.2466           5.6066            8.65m\n",
      "        40         307.9983           3.5467            8.49m\n",
      "        50         247.0959           1.1508            8.33m\n",
      "        60         207.0067           0.6126            8.23m\n",
      "        70         185.0395           0.6666            8.11m\n",
      "        80         163.6749           0.4723            7.97m\n",
      "        90         143.8663           0.3302            7.83m\n",
      "       100         127.6495           0.4822            7.69m\n",
      "       200          46.2674           0.0436            6.50m\n",
      "       300          20.0795           0.0154            7.38m\n",
      "       400           8.9763           0.0223            5.50m\n",
      "       500           3.9430           0.0011            3.94m\n",
      "       600           1.7575          -0.0018            2.79m\n",
      "       700           0.7357           0.0011            1.35m\n",
      "       800           0.3581           0.0003            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         943.6096          37.5309            8.82m\n",
      "         2         902.6872          33.0942            8.83m\n",
      "         3         864.1894          29.4472            8.82m\n",
      "         4         826.6532          25.7832            8.83m\n",
      "         5         795.4101          25.4304            8.82m\n",
      "         6         766.9801          21.7413            8.80m\n",
      "         7         736.6976          22.7729            8.80m\n",
      "         8         710.2988          19.4883            8.80m\n",
      "         9         683.5415          17.9153            8.80m\n",
      "        10         665.0704          16.7223            8.78m\n",
      "        20         492.9238           8.6319           12.71m\n",
      "        30         397.2893           4.6031           12.40m\n",
      "        40         317.5591           2.7098           12.03m\n",
      "        50         257.2662           1.7076           11.36m\n",
      "        60         218.9907           1.4716           10.71m\n",
      "        70         189.6592           0.8109           10.23m\n",
      "        80         167.0810           0.6437            9.82m\n",
      "        90         145.7043           0.5134            9.52m\n",
      "       100         132.8257           0.4795            9.21m\n",
      "       200          52.1073           0.0910            7.20m\n",
      "       300          20.1867           0.0162            5.81m\n",
      "       400           8.8822          -0.0023            4.64m\n",
      "       500           3.8309          -0.0024            3.53m\n",
      "       600           1.6596           0.0010            2.34m\n",
      "       700           0.7268          -0.0019            1.16m\n",
      "       800           0.3306           0.0003            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         942.6553          39.7895            9.03m\n",
      "         2         900.1082          35.2598            8.83m\n",
      "         3         859.9606          29.5874            8.82m\n",
      "         4         824.8285          25.8575            8.87m\n",
      "         5         795.1822          27.7998            8.90m\n",
      "         6         764.4233          22.4921            8.90m\n",
      "         7         740.3265          22.2259            8.91m\n",
      "         8         710.1696          18.6122            8.88m\n",
      "         9         685.9919          18.2121            8.86m\n",
      "        10         659.7002          17.9717            8.84m\n",
      "        20         480.5015           9.7343            8.68m\n",
      "        30         374.8460           4.9472            8.58m\n",
      "        40         308.7246           3.9334            8.45m\n",
      "        50         245.7090           2.4098            8.33m\n",
      "        60         203.3263           1.6664            8.21m\n",
      "        70         172.0175           1.0852            8.08m\n",
      "        80         152.3166           0.5348            7.97m\n",
      "        90         134.7294           0.3023            7.86m\n",
      "       100         118.2617           0.4287            7.74m\n",
      "       200          43.9205           0.0500            6.58m\n",
      "       300          19.1236           0.0039            5.47m\n",
      "       400           8.1944           0.0009            4.44m\n",
      "       500           3.3648           0.0022            3.36m\n",
      "       600           1.4871           0.0003            2.25m\n",
      "       700           0.6457          -0.0003            1.13m\n",
      "       800           0.3113          -0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         943.5069          35.6263            8.93m\n",
      "         2         902.8493          34.7960            8.79m\n",
      "         3         865.8466          31.2456            8.91m\n",
      "         4         829.6062          28.0685            8.89m\n",
      "         5         795.6790          24.6062            8.87m\n",
      "         6         764.4795          24.6210            8.84m\n",
      "         7         740.4262          23.4660            8.86m\n",
      "         8         712.0616          19.5900            8.89m\n",
      "         9         683.9186          17.9710            8.89m\n",
      "        10         664.9738          15.0632            8.92m\n",
      "        20         500.3897           9.0246            9.10m\n",
      "        30         389.1196           5.3242            9.27m\n",
      "        40         313.8016           2.4236            9.19m\n",
      "        50         266.0425           1.4555            9.09m\n",
      "        60         217.3004           1.6200            8.98m\n",
      "        70         193.6386           0.4589            8.83m\n",
      "        80         170.7463           0.7088            8.61m\n",
      "        90         150.4113           0.5530            8.42m\n",
      "       100         137.9169           0.1785            8.29m\n",
      "       200          51.9466          -0.0310            7.27m\n",
      "       300          22.5093          -0.0232            5.98m\n",
      "       400          10.4462           0.0021            4.70m\n",
      "       500           4.5578           0.0133            3.48m\n",
      "       600           2.1384           0.0001            2.30m\n",
      "       700           0.9451          -0.0002            1.15m\n",
      "       800           0.4459          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         943.5142          38.4938            8.80m\n",
      "         2         902.0953          35.9473            8.87m\n",
      "         3         861.3749          28.8992            8.83m\n",
      "         4         829.5783          29.8559            8.80m\n",
      "         5         793.2491          26.1222            8.83m\n",
      "         6         761.1657          23.6426            8.86m\n",
      "         7         732.2434          21.7797            8.89m\n",
      "         8         711.3411          21.2688            8.86m\n",
      "         9         678.1601          16.9817            8.83m\n",
      "        10         654.2508          16.8013            8.84m\n",
      "        20         493.2097           9.7838            8.86m\n",
      "        30         381.3389           5.5780            8.94m\n",
      "        40         296.2805           2.7869            8.83m\n",
      "        50         246.9393           2.2225            8.73m\n",
      "        60         216.9539           1.2779            8.56m\n",
      "        70         187.6993           0.6155            8.42m\n",
      "        80         161.7747           0.6214            8.26m\n",
      "        90         139.8631           0.6820            8.10m\n",
      "       100         131.4889           0.3181            7.96m\n",
      "       200          48.3181           0.0955            6.77m\n",
      "       300          19.7631          -0.0022            5.75m\n",
      "       400           7.8001           0.0093            4.64m\n",
      "       500           3.4691          -0.0015            3.49m\n",
      "       600           1.4786           0.0016            2.33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       700           0.6733           0.0009            1.16m\n",
      "       800           0.3111          -0.0002            0.00s\n"
     ]
    }
   ],
   "source": [
    "loss_scores_GBC= cross_val_score(gbc_model, X_train,y_train.argmax(axis=1),cv=5,scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         940.6012          38.6294            9.13m\n",
      "         2         899.6405          34.3466            9.03m\n",
      "         3         859.3907          31.2766            9.02m\n",
      "         4         821.5697          28.5191            8.98m\n",
      "         5         789.7491          23.3955            8.99m\n",
      "         6         765.2198          22.7179            8.96m\n",
      "         7         743.5247          22.0562            8.94m\n",
      "         8         705.0134          19.6982            8.95m\n",
      "         9         687.6270          18.2089            8.91m\n",
      "        10         661.9183          16.8484            8.91m\n",
      "        20         483.6423           7.7229            8.95m\n",
      "        30         388.5985           6.0148            9.31m\n",
      "        40         299.6932           2.7900            9.29m\n",
      "        50         246.4680           1.5163            9.12m\n",
      "        60         212.7034           1.1790            9.00m\n",
      "        70         178.8301           1.1420            8.81m\n",
      "        80         160.2996           0.6165            8.68m\n",
      "        90         139.5694           0.7583            8.50m\n",
      "       100         123.5721           0.1526            8.34m\n",
      "       200          47.3734           0.0288            7.24m\n",
      "       300          20.0860           0.0189            6.18m\n",
      "       400           8.7543           0.0054            4.88m\n",
      "       500           3.6676           0.0086            3.63m\n",
      "       600           1.7202           0.0012            2.42m\n",
      "       700           0.7583           0.0004            1.21m\n",
      "       800           0.3516          -0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         942.5961          38.8951            9.36m\n",
      "         2         902.5386          34.7681            9.61m\n",
      "         3         863.6347          31.8376            9.80m\n",
      "         4         825.5115          25.7685           10.36m\n",
      "         5         801.8674          25.3797           10.19m\n",
      "         6         765.2558          23.2496           10.04m\n",
      "         7         732.7174          20.2178            9.94m\n",
      "         8         715.8383          19.3685            9.83m\n",
      "         9         684.4693          18.6464            9.74m\n",
      "        10         670.3626          17.4585            9.66m\n",
      "        20         491.6368           8.8355            9.27m\n",
      "        30         393.5345           3.6428            9.05m\n",
      "        40         306.6571           3.2758            8.94m\n",
      "        50         254.3308           1.7848            8.82m\n",
      "        60         222.8741           1.0014            8.75m\n",
      "        70         192.7221           0.7343            8.66m\n",
      "        80         156.1723           0.6972            8.57m\n",
      "        90         142.6687           0.1374            8.41m\n",
      "       100         130.2568           0.3881            8.26m\n",
      "       200          48.1513           0.0971            7.11m\n",
      "       300          21.2169          -0.0022            5.86m\n",
      "       400           9.2724          -0.0063            4.63m\n",
      "       500           4.1449           0.0003            3.47m\n",
      "       600           1.7587           0.0005            2.32m\n",
      "       700           0.8168          -0.0000            1.15m\n",
      "       800           0.3672          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         941.9583          37.7832            9.05m\n",
      "         2         901.4514          32.7754            9.50m\n",
      "         3         863.8870          28.6611            9.85m\n",
      "         4         821.8263          27.7621            9.92m\n",
      "         5         797.2104          23.8654            9.81m\n",
      "         6         764.0411          23.5198            9.69m\n",
      "         7         738.7195          22.3227            9.81m\n",
      "         8         707.9390          19.4213            9.71m\n",
      "         9         692.6392          18.5211            9.67m\n",
      "        10         665.0009          16.7028            9.60m\n",
      "        20         483.9559           9.2291            9.39m\n",
      "        30         376.7967           5.8011            9.25m\n",
      "        40         305.5657           3.5568            9.05m\n",
      "        50         241.4486           2.3707            8.95m\n",
      "        60         216.3833           0.8934            8.82m\n",
      "        70         174.2886           0.9456            8.83m\n",
      "        80         155.0354           0.6511            8.63m\n",
      "        90         137.0946           0.7125            8.44m\n",
      "       100         116.0598           0.1769            8.32m\n",
      "       200          44.5341           0.0492            7.10m\n",
      "       300          17.6277           0.0071            5.88m\n",
      "       400           7.0118           0.0120            4.74m\n",
      "       500           3.0419          -0.0001            3.52m\n",
      "       600           1.2100          -0.0003            2.37m\n",
      "       700           0.5413          -0.0003            1.18m\n",
      "       800           0.2705           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         943.2555          37.0164            9.01m\n",
      "         2         901.2443          32.9304            9.13m\n",
      "         3         861.9262          29.9452            9.34m\n",
      "         4         826.5497          29.1153            9.26m\n",
      "         5         795.4899          25.0276            9.21m\n",
      "         6         768.1412          21.1220            9.17m\n",
      "         7         744.4746          20.0332            9.12m\n",
      "         8         712.9099          21.7820            9.08m\n",
      "         9         696.7040          16.2724            9.05m\n",
      "        10         666.5607          16.9081            9.01m\n",
      "        20         495.1638           8.0355            8.83m\n",
      "        30         389.5678           4.9240            8.80m\n",
      "        40         324.7146           3.3116            8.99m\n",
      "        50         270.2443           1.6631            9.00m\n",
      "        60         217.9539           1.0344            8.98m\n",
      "        70         198.6132           0.4216            8.82m\n",
      "        80         157.8000           0.3170            8.69m\n",
      "        90         153.7537           0.1073            8.51m\n",
      "       100         134.7786           0.0909            8.33m\n",
      "       200          53.2306           0.1459            6.95m\n",
      "       300          22.7938          -0.0023            5.74m\n",
      "       400          10.3564          -0.0044            4.63m\n",
      "       500           4.5029           0.0034            3.48m\n",
      "       600           1.9792           0.0005            2.33m\n",
      "       700           0.9348           0.0003            1.17m\n",
      "       800           0.4203          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         940.2047          38.5640            9.61m\n",
      "         2         897.3752          35.7907           10.63m\n",
      "         3         860.3861          31.1116           10.29m\n",
      "         4         829.0655          28.0579           10.02m\n",
      "         5         794.3880          26.3571           10.18m\n",
      "         6         763.6779          24.0689           10.40m\n",
      "         7         735.5025          21.9591           10.24m\n",
      "         8         709.4947          18.6984           10.14m\n",
      "         9         676.9534          19.5534           10.05m\n",
      "        10         665.5876          17.7550            9.95m\n",
      "        20         480.2404           8.7777            9.34m\n",
      "        30         387.1004           4.4338            9.08m\n",
      "        40         298.3874           3.0814            9.07m\n",
      "        50         259.2604           1.5714            8.88m\n",
      "        60         215.9411           0.8194            8.70m\n",
      "        70         187.1737           0.9950            8.55m\n",
      "        80         153.1757           0.7742            8.39m\n",
      "        90         134.7128           0.4289            8.29m\n",
      "       100         128.5724           0.2194            8.17m\n",
      "       200          41.7232           0.0298            7.50m\n",
      "       300          19.1156           0.0154            6.08m\n",
      "       400           8.1664           0.0142            4.77m\n",
      "       500           3.4273          -0.0031            3.58m\n",
      "       600           1.5179          -0.0012            2.39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       700           0.6578          -0.0001            1.19m\n",
      "       800           0.3033           0.0002            0.00s\n"
     ]
    }
   ],
   "source": [
    "scores_acc_GBC = cross_val_score(gbc_model, X_train,y_train.argmax(axis=1),cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5898052036963848"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_scores_GBC.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166666666666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_acc_GBC.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add relu layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense,GlobalAveragePooling2D,BatchNormalization\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import accuracy_score,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "1440/1440 [==============================] - 5s 3ms/step - loss: 0.8000 - acc: 0.6792\n",
      "Epoch 2/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.3871 - acc: 0.8646\n",
      "Epoch 3/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2899 - acc: 0.9132\n",
      "Epoch 4/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2041 - acc: 0.9486\n",
      "Epoch 5/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1718 - acc: 0.9528\n",
      "Epoch 6/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1356 - acc: 0.9729\n",
      "Epoch 7/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1126 - acc: 0.9826\n",
      "Epoch 8/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0885 - acc: 0.9889\n",
      "Epoch 9/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0849 - acc: 0.9903\n",
      "Epoch 10/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0759 - acc: 0.9924A: 0s - loss: 0.0768 -\n",
      "Epoch 11/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0694 - acc: 0.9903\n",
      "Epoch 12/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0534 - acc: 0.9986\n",
      "Epoch 13/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0575 - acc: 0.9958\n",
      "Epoch 14/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0450 - acc: 0.9986\n",
      "Epoch 15/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0518 - acc: 0.9931\n",
      "Epoch 16/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0436 - acc: 0.9972\n",
      "Epoch 17/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0410 - acc: 0.9972\n",
      "Epoch 18/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0411 - acc: 0.9965\n",
      "Epoch 1/18\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.7985 - acc: 0.6757\n",
      "Epoch 2/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.3822 - acc: 0.8660A: 1s - loss\n",
      "Epoch 3/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2840 - acc: 0.9069\n",
      "Epoch 4/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2107 - acc: 0.9424\n",
      "Epoch 5/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1741 - acc: 0.9479\n",
      "Epoch 6/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1332 - acc: 0.9729\n",
      "Epoch 7/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1146 - acc: 0.9792\n",
      "Epoch 8/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0947 - acc: 0.9910\n",
      "Epoch 9/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0870 - acc: 0.9910\n",
      "Epoch 10/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0829 - acc: 0.9917\n",
      "Epoch 11/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0666 - acc: 0.9944\n",
      "Epoch 12/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0630 - acc: 0.9951\n",
      "Epoch 13/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0589 - acc: 0.9958\n",
      "Epoch 14/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0500 - acc: 0.9979\n",
      "Epoch 15/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0446 - acc: 0.9972\n",
      "Epoch 16/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0433 - acc: 0.9979\n",
      "Epoch 17/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0427 - acc: 0.9986\n",
      "Epoch 18/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0357 - acc: 0.9986\n",
      "Epoch 1/18\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.8054 - acc: 0.6743\n",
      "Epoch 2/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.3918 - acc: 0.8646\n",
      "Epoch 3/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2840 - acc: 0.9069\n",
      "Epoch 4/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2183 - acc: 0.9361\n",
      "Epoch 5/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1792 - acc: 0.9562\n",
      "Epoch 6/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1430 - acc: 0.9743\n",
      "Epoch 7/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1136 - acc: 0.9806\n",
      "Epoch 8/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1013 - acc: 0.9875\n",
      "Epoch 9/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0921 - acc: 0.9854\n",
      "Epoch 10/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0719 - acc: 0.9965\n",
      "Epoch 11/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0753 - acc: 0.9910\n",
      "Epoch 12/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0558 - acc: 0.9958\n",
      "Epoch 13/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0532 - acc: 0.9979\n",
      "Epoch 14/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0538 - acc: 0.9965\n",
      "Epoch 15/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0443 - acc: 0.9993\n",
      "Epoch 16/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 17/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0398 - acc: 0.9986\n",
      "Epoch 18/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0442 - acc: 0.9972\n",
      "Epoch 1/18\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.8052 - acc: 0.6674\n",
      "Epoch 2/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4155 - acc: 0.8507\n",
      "Epoch 3/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2790 - acc: 0.9111\n",
      "Epoch 4/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2145 - acc: 0.9486\n",
      "Epoch 5/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1832 - acc: 0.9528A: 0s - loss: 0.1745 - ac\n",
      "Epoch 6/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1473 - acc: 0.9694\n",
      "Epoch 7/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1183 - acc: 0.9833\n",
      "Epoch 8/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0989 - acc: 0.9875\n",
      "Epoch 9/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0936 - acc: 0.9882\n",
      "Epoch 10/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0844 - acc: 0.9903\n",
      "Epoch 11/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0754 - acc: 0.9937\n",
      "Epoch 12/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0641 - acc: 0.9931\n",
      "Epoch 13/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0516 - acc: 0.9986\n",
      "Epoch 14/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0601 - acc: 0.9931\n",
      "Epoch 15/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0473 - acc: 0.9958\n",
      "Epoch 16/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0461 - acc: 0.9986\n",
      "Epoch 17/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0451 - acc: 0.9972\n",
      "Epoch 18/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0369 - acc: 0.9986\n",
      "Epoch 1/18\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.7940 - acc: 0.6799A: 0s - loss: 0.8464 - acc: 0\n",
      "Epoch 2/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.3912 - acc: 0.8583\n",
      "Epoch 3/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2730 - acc: 0.9118\n",
      "Epoch 4/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2191 - acc: 0.9382\n",
      "Epoch 5/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1686 - acc: 0.9535\n",
      "Epoch 6/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1325 - acc: 0.9743\n",
      "Epoch 7/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.1156 - acc: 0.9778\n",
      "Epoch 8/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0965 - acc: 0.9910A: 0s - loss: 0.0960 - acc: 0.99\n",
      "Epoch 9/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0816 - acc: 0.9917\n",
      "Epoch 10/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0812 - acc: 0.9896\n",
      "Epoch 11/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0690 - acc: 0.9910\n",
      "Epoch 12/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0644 - acc: 0.9931\n",
      "Epoch 13/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0534 - acc: 0.9972\n",
      "Epoch 14/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0539 - acc: 0.9986\n",
      "Epoch 15/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0489 - acc: 0.9958\n",
      "Epoch 16/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0427 - acc: 0.9979\n",
      "Epoch 17/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0428 - acc: 0.9986\n",
      "Epoch 18/18\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.0381 - acc: 0.9993\n"
     ]
    }
   ],
   "source": [
    "ll=[]\n",
    "accu=[]\n",
    "for train_index, test_index in skf.split(X_train, y_train.argmax(axis=1)):\n",
    "    my_model = Sequential()\n",
    "    my_model.add(BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "    my_model.add(Dense(1024, activation = \"relu\"))\n",
    "    my_model.add(Dense(4, activation='softmax'))\n",
    "    my_model.compile(optimizer=\"SGD\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    my_model.fit(X_train[train_index], y_train[train_index],epochs=18,batch_size=30,verbose=1)\n",
    "    \n",
    "    prediction=my_model.predict(X_train[test_index])\n",
    "    logloss=log_loss(y_train[test_index],prediction)\n",
    "    ll.append(logloss)\n",
    "    acc=accuracy_score(y_train.argmax(axis=1)[test_index],prediction.argmax(axis=1))\n",
    "    accu.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss=sum(ll)/len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=sum(accu)/len(accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_model=RandomForestClassifier(n_estimators=700,\n",
    "                                    max_depth=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   19.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model.fit(X_train,y_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   11.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   19.0s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[2,3,5]}\n",
    "clf = GridSearchCV(my_model4, parameters,scoring='neg_log_loss')\n",
    "clf.fit(X_train,y_train)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "loss_scores_RF = cross_val_score(RF_model, X_train,y_train,cv=5,scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   14.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "scores_acc_RF = cross_val_score(RF_model, X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8834106430150653"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_scores_RF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_acc_RF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d96f75f9309a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_acc_RF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_acc_RF' is not defined"
     ]
    }
   ],
   "source": [
    "scores_acc_RF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
